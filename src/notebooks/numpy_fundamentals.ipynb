{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NumPy Fundamentals for Machine Learning\n",
        "\n",
        "NumPy (Numerical Python) is the foundation of scientific computing in Python. It provides high-performance multidimensional arrays and mathematical functions that are essential for machine learning and data science.\n",
        "\n",
        "## Why NumPy Matters for ML\n",
        "\n",
        "- **Performance**: Vectorized operations in C, orders of magnitude faster than pure Python\n",
        "- **Memory Efficiency**: Homogeneous arrays with fixed data types\n",
        "- **Broadcasting**: Elegant handling of operations between different-shaped arrays\n",
        "- **Foundation**: Almost all ML libraries (scikit-learn, TensorFlow, PyTorch) are built on NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# Display NumPy version and configuration\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"NumPy configuration:\")\n",
        "np.show_config()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Array Creation and Basic Operations\n",
        "\n",
        "Understanding different ways to create and manipulate arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different ways to create arrays\n",
        "print(\"=== Array Creation ===\")\n",
        "\n",
        "# From lists\n",
        "arr1 = np.array([1, 2, 3, 4, 5])\n",
        "arr2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(f\"1D array: {arr1}\")\n",
        "print(f\"2D array:\\n{arr2}\")\n",
        "print(f\"Shape: {arr2.shape}, Dimensions: {arr2.ndim}, Size: {arr2.size}\")\n",
        "\n",
        "# Common array creation functions\n",
        "zeros = np.zeros((3, 4))\n",
        "ones = np.ones((2, 3))\n",
        "identity = np.eye(3)\n",
        "random_arr = np.random.random((2, 3))\n",
        "arange_arr = np.arange(0, 10, 2)\n",
        "linspace_arr = np.linspace(0, 1, 5)\n",
        "\n",
        "print(f\"\\nZeros:\\n{zeros}\")\n",
        "print(f\"\\nIdentity matrix:\\n{identity}\")\n",
        "print(f\"\\nRandom array:\\n{random_arr}\")\n",
        "print(f\"\\nArange: {arange_arr}\")\n",
        "print(f\"Linspace: {linspace_arr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Types and Memory Optimization\n",
        "\n",
        "Understanding dtypes is crucial for memory efficiency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data types comparison\n",
        "print(\"=== Data Types and Memory ===\")\n",
        "\n",
        "# Different precision arrays\n",
        "arr_int32 = np.array([1, 2, 3, 4, 5], dtype=np.int32)\n",
        "arr_int64 = np.array([1, 2, 3, 4, 5], dtype=np.int64)\n",
        "arr_float32 = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
        "arr_float64 = np.array([1.0, 2.0, 3.0], dtype=np.float64)\n",
        "\n",
        "print(f\"Int32 memory: {arr_int32.nbytes} bytes\")\n",
        "print(f\"Int64 memory: {arr_int64.nbytes} bytes\")\n",
        "print(f\"Float32 memory: {arr_float32.nbytes} bytes\")\n",
        "print(f\"Float64 memory: {arr_float64.nbytes} bytes\")\n",
        "\n",
        "# Memory efficiency example with large arrays\n",
        "large_float64 = np.random.random(1000000)\n",
        "large_float32 = large_float64.astype(np.float32)\n",
        "\n",
        "print(f\"\\nLarge array (float64): {large_float64.nbytes / 1024**2:.1f} MB\")\n",
        "print(f\"Large array (float32): {large_float32.nbytes / 1024**2:.1f} MB\")\n",
        "print(f\"Memory savings: {(1 - large_float32.nbytes/large_float64.nbytes)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Array Indexing and Slicing\n",
        "\n",
        "Powerful ways to access and modify array elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample array for indexing examples\n",
        "matrix = np.arange(24).reshape(4, 6)\n",
        "print(\"Sample matrix:\")\n",
        "print(matrix)\n",
        "\n",
        "print(\"\\n=== Basic Indexing ===\")\n",
        "print(f\"Element at (1, 2): {matrix[1, 2]}\")\n",
        "print(f\"Second row: {matrix[1, :]}\")\n",
        "print(f\"Third column: {matrix[:, 2]}\")\n",
        "print(f\"Submatrix (rows 1-2, cols 2-4):\\n{matrix[1:3, 2:5]}\")\n",
        "\n",
        "print(\"\\n=== Advanced Indexing ===\")\n",
        "# Boolean indexing\n",
        "condition = matrix > 10\n",
        "print(f\"Elements > 10: {matrix[condition]}\")\n",
        "\n",
        "# Fancy indexing\n",
        "rows = [0, 2, 3]\n",
        "cols = [1, 3, 5]\n",
        "print(f\"Selected elements: {matrix[rows, cols]}\")\n",
        "\n",
        "# Negative indexing\n",
        "print(f\"Last element: {matrix[-1, -1]}\")\n",
        "print(f\"Last row: {matrix[-1, :]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Broadcasting: The Power of NumPy\n",
        "\n",
        "Broadcasting allows operations between arrays of different shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Broadcasting Examples ===\")\n",
        "\n",
        "# Basic broadcasting\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "scalar = 10\n",
        "print(f\"Original array:\\n{arr}\")\n",
        "print(f\"Array + scalar:\\n{arr + scalar}\")\n",
        "\n",
        "# Vector broadcasting\n",
        "vector = np.array([10, 20, 30])\n",
        "print(f\"\\nVector: {vector}\")\n",
        "print(f\"Array + vector:\\n{arr + vector}\")\n",
        "\n",
        "# More complex broadcasting\n",
        "matrix_a = np.array([[1], [2], [3]])  # (3, 1)\n",
        "matrix_b = np.array([10, 20])         # (2,)\n",
        "result = matrix_a + matrix_b          # Results in (3, 2)\n",
        "\n",
        "print(f\"\\nMatrix A (3,1):\\n{matrix_a}\")\n",
        "print(f\"Matrix B (2,): {matrix_b}\")\n",
        "print(f\"Broadcasted result (3,2):\\n{result}\")\n",
        "\n",
        "# Practical example: Normalizing data\n",
        "data = np.random.randn(100, 3)  # 100 samples, 3 features\n",
        "mean = np.mean(data, axis=0)    # Mean of each feature\n",
        "std = np.std(data, axis=0)      # Std of each feature\n",
        "\n",
        "# Broadcasting for standardization\n",
        "normalized_data = (data - mean) / std\n",
        "\n",
        "print(f\"\\nData shape: {data.shape}\")\n",
        "print(f\"Original means: {np.mean(data, axis=0)}\")\n",
        "print(f\"Normalized means: {np.mean(normalized_data, axis=0)}\")\n",
        "print(f\"Normalized stds: {np.std(normalized_data, axis=0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Mathematical Operations and Linear Algebra\n",
        "\n",
        "Essential operations for machine learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Mathematical Operations ===\")\n",
        "\n",
        "# Element-wise operations\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([5, 6, 7, 8])\n",
        "\n",
        "print(f\"a = {a}\")\n",
        "print(f\"b = {b}\")\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "print(f\"a ** 2 = {a ** 2}\")\n",
        "\n",
        "# Aggregation functions\n",
        "matrix = np.random.randn(4, 5)\n",
        "print(f\"\\nSample matrix:\\n{matrix}\")\n",
        "print(f\"Sum: {np.sum(matrix)}\")\n",
        "print(f\"Mean: {np.mean(matrix):.3f}\")\n",
        "print(f\"Std: {np.std(matrix):.3f}\")\n",
        "print(f\"Sum along axis 0: {np.sum(matrix, axis=0)}\")\n",
        "print(f\"Sum along axis 1: {np.sum(matrix, axis=1)}\")\n",
        "\n",
        "print(\"\\n=== Linear Algebra ===\")\n",
        "\n",
        "# Matrix operations\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "print(f\"Matrix A:\\n{A}\")\n",
        "print(f\"Matrix B:\\n{B}\")\n",
        "print(f\"Matrix multiplication A @ B:\\n{A @ B}\")\n",
        "print(f\"Element-wise multiplication A * B:\\n{A * B}\")\n",
        "\n",
        "# Important linear algebra operations\n",
        "print(f\"\\nDeterminant of A: {np.linalg.det(A):.3f}\")\n",
        "print(f\"Inverse of A:\\n{np.linalg.inv(A)}\")\n",
        "print(f\"Eigenvalues: {np.linalg.eigvals(A)}\")\n",
        "\n",
        "# Vector operations\n",
        "v1 = np.array([1, 2, 3])\n",
        "v2 = np.array([4, 5, 6])\n",
        "\n",
        "print(f\"\\nVector v1: {v1}\")\n",
        "print(f\"Vector v2: {v2}\")\n",
        "print(f\"Dot product: {np.dot(v1, v2)}\")\n",
        "print(f\"Cross product: {np.cross(v1, v2)}\")\n",
        "print(f\"L2 norm of v1: {np.linalg.norm(v1):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Performance Comparison: NumPy vs Pure Python\n",
        "\n",
        "Demonstrating why NumPy is essential for ML:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance comparison\n",
        "size = 1000000\n",
        "python_list = list(range(size))\n",
        "numpy_array = np.arange(size)\n",
        "\n",
        "print(f\"=== Performance Comparison (n={size:,}) ===\")\n",
        "\n",
        "# Sum operation\n",
        "start_time = time.time()\n",
        "python_sum = sum(python_list)\n",
        "python_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "numpy_sum = np.sum(numpy_array)\n",
        "numpy_time = time.time() - start_time\n",
        "\n",
        "print(f\"Sum operation:\")\n",
        "print(f\"  Python list: {python_time:.4f} seconds\")\n",
        "print(f\"  NumPy array: {numpy_time:.4f} seconds\")\n",
        "print(f\"  Speedup: {python_time / numpy_time:.1f}x\")\n",
        "\n",
        "# Element-wise operations\n",
        "python_list_small = list(range(10000))\n",
        "numpy_array_small = np.arange(10000)\n",
        "\n",
        "# Square all elements\n",
        "start_time = time.time()\n",
        "python_squared = [x**2 for x in python_list_small]\n",
        "python_square_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "numpy_squared = numpy_array_small ** 2\n",
        "numpy_square_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nSquaring elements (n={len(python_list_small):,}):\")\n",
        "print(f\"  Python list: {python_square_time:.4f} seconds\")\n",
        "print(f\"  NumPy array: {numpy_square_time:.4f} seconds\")\n",
        "print(f\"  Speedup: {python_square_time / numpy_square_time:.1f}x\")\n",
        "\n",
        "# Memory usage comparison\n",
        "import sys\n",
        "python_memory = sys.getsizeof(python_list_small)\n",
        "numpy_memory = numpy_array_small.nbytes\n",
        "\n",
        "print(f\"\\nMemory usage (n={len(python_list_small):,}):\")\n",
        "print(f\"  Python list: {python_memory:,} bytes\")\n",
        "print(f\"  NumPy array: {numpy_memory:,} bytes\")\n",
        "print(f\"  Memory savings: {(1 - numpy_memory/python_memory)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Practical ML Examples with NumPy\n",
        "\n",
        "Real-world applications in machine learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ML Applications with NumPy ===\")\n",
        "\n",
        "# 1. Distance calculations (crucial for KNN, clustering)\n",
        "def euclidean_distance(point1, point2):\n",
        "    \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "# Example: Finding nearest neighbors\n",
        "data_points = np.random.randn(100, 2)  # 100 points in 2D\n",
        "query_point = np.array([0.5, 0.5])\n",
        "\n",
        "# Vectorized distance calculation\n",
        "distances = np.sqrt(np.sum((data_points - query_point) ** 2, axis=1))\n",
        "nearest_idx = np.argmin(distances)\n",
        "\n",
        "print(f\"Query point: {query_point}\")\n",
        "print(f\"Nearest neighbor: {data_points[nearest_idx]}\")\n",
        "print(f\"Distance: {distances[nearest_idx]:.3f}\")\n",
        "\n",
        "# 2. Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
        "    return exp_x / np.sum(exp_x)\n",
        "\n",
        "# Test activation functions\n",
        "x = np.linspace(-5, 5, 100)\n",
        "sigmoid_values = sigmoid(x)\n",
        "relu_values = relu(x)\n",
        "\n",
        "# Softmax example\n",
        "logits = np.array([2.0, 1.0, 0.1])\n",
        "probabilities = softmax(logits)\n",
        "print(f\"\\nLogits: {logits}\")\n",
        "print(f\"Softmax probabilities: {probabilities}\")\n",
        "print(f\"Sum of probabilities: {np.sum(probabilities)}\")\n",
        "\n",
        "# 3. Mini-batch gradient descent simulation\n",
        "def generate_linear_data(n_samples, noise=0.1):\n",
        "    \"\"\"Generate synthetic linear data\"\"\"\n",
        "    X = np.random.randn(n_samples, 1)\n",
        "    y = 2 * X.squeeze() + 1 + noise * np.random.randn(n_samples)\n",
        "    return X, y\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    \"\"\"Mean squared error loss\"\"\"\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Generate data\n",
        "X, y = generate_linear_data(100)\n",
        "X_with_bias = np.c_[np.ones(X.shape[0]), X]  # Add bias term\n",
        "\n",
        "# Initialize parameters\n",
        "theta = np.random.randn(2)\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "print(f\"\\n=== Mini-batch Gradient Descent ===\")\n",
        "print(f\"Initial parameters: {theta}\")\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # Shuffle data\n",
        "    indices = np.random.permutation(len(X))\n",
        "    X_shuffled = X_with_bias[indices]\n",
        "    y_shuffled = y[indices]\n",
        "    \n",
        "    # Mini-batch updates\n",
        "    for i in range(0, len(X), batch_size):\n",
        "        X_batch = X_shuffled[i:i+batch_size]\n",
        "        y_batch = y_shuffled[i:i+batch_size]\n",
        "        \n",
        "        # Forward pass\n",
        "        y_pred = X_batch @ theta\n",
        "        \n",
        "        # Compute gradient\n",
        "        gradient = (2/len(X_batch)) * X_batch.T @ (y_pred - y_batch)\n",
        "        \n",
        "        # Update parameters\n",
        "        theta -= learning_rate * gradient\n",
        "    \n",
        "    if epoch % 20 == 0:\n",
        "        y_pred_full = X_with_bias @ theta\n",
        "        loss = mse_loss(y, y_pred_full)\n",
        "        print(f\"Epoch {epoch:2d}: Loss = {loss:.4f}, Î¸ = {theta}\")\n",
        "\n",
        "print(f\"Final parameters: {theta}\")\n",
        "print(f\"True parameters: [1, 2] (bias, weight)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Advanced NumPy: Tips and Tricks\n",
        "\n",
        "Professional techniques for efficient code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Advanced NumPy Techniques ===\")\n",
        "\n",
        "# 1. Vectorization vs loops\n",
        "def slow_function(arr):\n",
        "    \"\"\"Slow implementation using loops\"\"\"\n",
        "    result = np.zeros_like(arr)\n",
        "    for i in range(len(arr)):\n",
        "        for j in range(len(arr[0])):\n",
        "            result[i, j] = arr[i, j] ** 2 + np.sin(arr[i, j])\n",
        "    return result\n",
        "\n",
        "def fast_function(arr):\n",
        "    \"\"\"Fast vectorized implementation\"\"\"\n",
        "    return arr ** 2 + np.sin(arr)\n",
        "\n",
        "# Compare performance\n",
        "test_array = np.random.randn(100, 100)\n",
        "\n",
        "start_time = time.time()\n",
        "slow_result = slow_function(test_array)\n",
        "slow_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "fast_result = fast_function(test_array)\n",
        "fast_time = time.time() - start_time\n",
        "\n",
        "print(f\"Slow function: {slow_time:.4f} seconds\")\n",
        "print(f\"Fast function: {fast_time:.4f} seconds\")\n",
        "print(f\"Speedup: {slow_time / fast_time:.1f}x\")\n",
        "print(f\"Results equal: {np.allclose(slow_result, fast_result)}\")\n",
        "\n",
        "# 2. Memory views and copying\n",
        "original = np.arange(12).reshape(3, 4)\n",
        "view = original[1:, 1:]  # This is a view, not a copy\n",
        "copy = original[1:, 1:].copy()  # This is a copy\n",
        "\n",
        "print(f\"\\nOriginal array:\\n{original}\")\n",
        "print(f\"View shares memory: {np.shares_memory(original, view)}\")\n",
        "print(f\"Copy shares memory: {np.shares_memory(original, copy)}\")\n",
        "\n",
        "# Modify view - affects original\n",
        "view[0, 0] = 999\n",
        "print(f\"After modifying view:\\n{original}\")\n",
        "\n",
        "# 3. Efficient array operations\n",
        "print(\"\\n=== Efficient Operations ===\")\n",
        "\n",
        "# Use np.where for conditional operations\n",
        "arr = np.random.randn(10)\n",
        "# Instead of: [x if x > 0 else 0 for x in arr]\n",
        "clipped = np.where(arr > 0, arr, 0)\n",
        "print(f\"Original: {arr}\")\n",
        "print(f\"Clipped:  {clipped}\")\n",
        "\n",
        "# Use np.clip for range limiting\n",
        "bounded = np.clip(arr, -1, 1)\n",
        "print(f\"Bounded:  {bounded}\")\n",
        "\n",
        "# 4. Useful array manipulations\n",
        "matrix = np.arange(12).reshape(3, 4)\n",
        "print(f\"\\nOriginal matrix:\\n{matrix}\")\n",
        "print(f\"Flattened: {matrix.flatten()}\")\n",
        "print(f\"Transposed:\\n{matrix.T}\")\n",
        "print(f\"Reshaped (2, 6):\\n{matrix.reshape(2, 6)}\")\n",
        "\n",
        "# Stack operations\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "print(f\"\\nVertical stack:\\n{np.vstack([a, b])}\")\n",
        "print(f\"Horizontal stack: {np.hstack([a, b])}\")\n",
        "\n",
        "# 5. Boolean indexing tricks\n",
        "data = np.random.randn(100)\n",
        "outliers = np.abs(data) > 2  # Boolean mask\n",
        "print(f\"\\nNumber of outliers (>2Ïƒ): {np.sum(outliers)}\")\n",
        "print(f\"Outlier values: {data[outliers]}\")\n",
        "\n",
        "# Multiple conditions\n",
        "moderate = (np.abs(data) > 1) & (np.abs(data) < 2)\n",
        "print(f\"Moderate values (1Ïƒ < |x| < 2Ïƒ): {np.sum(moderate)} values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways and Best Practices\n",
        "\n",
        "### ğŸ¯ **Performance Principles**\n",
        "1. **Vectorize operations**: Avoid explicit loops when possible\n",
        "2. **Use appropriate data types**: `float32` vs `float64`, `int32` vs `int64`\n",
        "3. **Understand views vs copies**: Use views to save memory, copies for safety\n",
        "4. **Leverage broadcasting**: Elegant and efficient operations between different shapes\n",
        "\n",
        "### ğŸ§® **Mathematical Operations**\n",
        "- **Element-wise**: `+`, `-`, `*`, `/`, `**`\n",
        "- **Matrix operations**: `@` for matrix multiplication, `np.linalg` for advanced operations\n",
        "- **Aggregations**: `np.sum()`, `np.mean()`, `np.std()` with axis parameters\n",
        "- **Comparisons**: `>`, `<`, `==` return boolean arrays for masking\n",
        "\n",
        "### ğŸ› ï¸ **Essential Functions for ML**\n",
        "```python\n",
        "# Array creation\n",
        "np.zeros(), np.ones(), np.random.randn(), np.linspace()\n",
        "\n",
        "# Reshaping\n",
        "arr.reshape(), arr.flatten(), arr.T\n",
        "\n",
        "# Indexing\n",
        "arr[mask], arr[indices], arr[:, 1:3]\n",
        "\n",
        "# Math\n",
        "np.sum(), np.mean(), np.std(), np.dot(), np.linalg.norm()\n",
        "\n",
        "# Utilities\n",
        "np.where(), np.clip(), np.argmax(), np.argsort()\n",
        "```\n",
        "\n",
        "### ğŸš€ **Memory and Performance Tips**\n",
        "1. **Pre-allocate arrays** when size is known\n",
        "2. **Use in-place operations** when possible (`+=`, `*=`)\n",
        "3. **Choose appropriate precision** based on your needs\n",
        "4. **Profile your code** to identify bottlenecks\n",
        "\n",
        "### ğŸ”— **Integration with ML Libraries**\n",
        "- **Scikit-learn**: Expects NumPy arrays as input\n",
        "- **TensorFlow/PyTorch**: Convert easily with `.numpy()` and tensor constructors  \n",
        "- **Pandas**: Built on NumPy, seamless integration\n",
        "- **Matplotlib**: Native NumPy array plotting\n",
        "\n",
        "NumPy mastery is fundamental for effective machine learning in Python. These concepts form the foundation for understanding and implementing ML algorithms efficiently!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}